{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Masoscience\n",
        "\n",
        "**Author:** Mir Yasin Zeinaliyan\n",
        "\n",
        "**Email:** yasinprodebian@gmail.com  \n",
        "\n",
        "**Github:** https://github.com/yasin-pro/masoscience\n",
        "\n",
        "**Description:** Masoscience is a project in which, with the help of data analysis and deep learning and advanced concepts related to it and even concepts related to the stock market, a model has been implemented to predict the increase or decrease in price, but it has a lot of work to do.\n"
      ],
      "metadata": {
        "id": "Wf_qQ5dZJ5l6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kczedMgc6yq"
      },
      "source": [
        "### import libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UfVv5K4p4A1J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42Cbsb3BoH47"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzhOmCYrcgLX"
      },
      "source": [
        "### read data (this data collectted from meta trader 5)\n",
        "\n",
        "##### EURUSD 1H\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YN4z6_92clgf"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data.csv\")\n",
        "\n",
        "df['time'] = pd.to_datetime(df['time'])\n",
        "\n",
        "df = df.sort_values(by='time')\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "df = df[['open', 'high', 'low', 'close']].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d20htJ224JyQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvBFddr1cIEz"
      },
      "source": [
        "### calculate Rsi for 14, 16, 18, 20 period time\n",
        "\n",
        "The Relative Strength Index (RSI) is a momentum oscillator used in technical analysis to measure the speed and change of price movements. It was developed by J. Welles Wilder and is designed to identify overbought or oversold conditions in a market."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3aqJSmfcQ8Q"
      },
      "outputs": [],
      "source": [
        "def calculate_rsi(data, period=14):\n",
        "    \"\"\"This function for calculate rsi.\"\"\"\n",
        "\n",
        "    close_prices = data['close']\n",
        "\n",
        "    daily_returns = close_prices.diff()\n",
        "\n",
        "    gain = daily_returns.where(daily_returns > 0, 0)\n",
        "\n",
        "    loss = -daily_returns.where(daily_returns < 0, 0)\n",
        "\n",
        "    average_gain = gain.rolling(window=period).mean()\n",
        "\n",
        "    average_loss = loss.rolling(window=period).mean()\n",
        "\n",
        "    rs = average_gain / average_loss\n",
        "\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "\n",
        "    return rsi\n",
        "\n",
        "df[\"rsi_14\"] = calculate_rsi(df, 14)\n",
        "\n",
        "df[\"rsi_16\"] = calculate_rsi(df, 16)\n",
        "\n",
        "df[\"rsi_18\"] = calculate_rsi(df, 18)\n",
        "\n",
        "df[\"rsi_20\"] = calculate_rsi(df, 20)\n",
        "\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9-B7_a1jHDG"
      },
      "source": [
        "### calculate Bollinger Bands for 18, 20, 22, 24 period\n",
        "\n",
        "Bollinger Bands are a technical analysis tool developed by John Bollinger, used to measure market volatility and identify potential overbought or oversold conditions. Bollinger Bands consist of three lines, typically plotted on a price chart:\n",
        "\n",
        "    Middle Band: This is usually a simple moving average (SMA) of the price, typically set to 20 periods.\n",
        "\n",
        "    Upper Band: This is calculated by adding a certain number of standard deviations (usually 2) to the middle band. The standard deviation measures the dispersion of price data from the average.\n",
        "\n",
        "    Lower Band: This is calculated by subtracting the same number of standard deviations (usually 2) from the middle band.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tG35xGnvjTXO"
      },
      "outputs": [],
      "source": [
        "def calculate_bollinger_bands(data, period=20):\n",
        "    \"\"\"\n",
        "    THIS FUNCTION FOR CALCULATE BOLLINGER BANDS\n",
        "    \"\"\"\n",
        "    close_prices = data['close']\n",
        "\n",
        "    sma = close_prices.rolling(window=period).mean()\n",
        "\n",
        "    std = close_prices.rolling(window=period).std()\n",
        "\n",
        "    upper_band = sma + 2 * std\n",
        "\n",
        "    lower_band = sma - 2 * std\n",
        "\n",
        "    return upper_band, sma, lower_band\n",
        "\n",
        "upper_band, sma, lower_band = calculate_bollinger_bands(df, 18)\n",
        "\n",
        "df['upper_band_18'] = upper_band\n",
        "\n",
        "df['sma_18'] = sma\n",
        "\n",
        "df['lower_band_18'] = lower_band\n",
        "\n",
        "upper_band, sma, lower_band = calculate_bollinger_bands(df, 20)\n",
        "\n",
        "df['upper_band_20'] = upper_band\n",
        "\n",
        "df['sma_20'] = sma\n",
        "\n",
        "df['lower_band_20'] = lower_band\n",
        "\n",
        "upper_band, sma, lower_band = calculate_bollinger_bands(df, 22)\n",
        "\n",
        "df['upper_band_22'] = upper_band\n",
        "\n",
        "df['sma_22'] = sma\n",
        "\n",
        "df['lower_band_22'] = lower_band\n",
        "\n",
        "upper_band, sma, lower_band = calculate_bollinger_bands(df, 24)\n",
        "\n",
        "df['upper_band_24'] = upper_band\n",
        "\n",
        "df['sma_24'] = sma\n",
        "\n",
        "df['lower_band_24'] = lower_band\n",
        "\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amKEKngYSnSJ"
      },
      "source": [
        "### calculate ATR for period (14, 16, 18, 20)\n",
        "\n",
        "ATR (Average True Range) is a technical analysis indicator that measures market volatility by analyzing the range of an asset's price over a specific period. It was developed by J. Welles Wilder and introduced in his 1978 book \"New Concepts in Technical Trading Systems.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOiQVkZPSw3t"
      },
      "outputs": [],
      "source": [
        "def calculate_atr_14(df, atr_period=14):\n",
        "    \"\"\"\n",
        "    THIS FUNCTION FOR CALCULATE ATR\n",
        "    \"\"\"\n",
        "    df['TR'] = df.apply(\n",
        "        lambda row: max(\n",
        "            row['high'] - row['low'], abs(\n",
        "                row['high'] - row['close']\n",
        "            ),\n",
        "            abs(\n",
        "                row['low'] - row['close']\n",
        "            )\n",
        "        ), axis=1\n",
        "    )\n",
        "\n",
        "    df['atr_14'] = df['TR'].rolling(window=atr_period).mean()\n",
        "\n",
        "    df.drop('TR', axis=1, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "def calculate_atr_16(df, atr_period=16):\n",
        "    \"\"\"\n",
        "    THIS FUNCTION FOR CALCULATE ATR\n",
        "    \"\"\"\n",
        "    df['TR'] = df.apply(\n",
        "        lambda row: max(\n",
        "            row['high'] - row['low'], abs(\n",
        "                row['high'] - row['close']\n",
        "            ),\n",
        "            abs(\n",
        "                row['low'] - row['close']\n",
        "            )\n",
        "        ), axis=1\n",
        "    )\n",
        "\n",
        "    df['atr_16'] = df['TR'].rolling(window=atr_period).mean()\n",
        "\n",
        "    df.drop('TR', axis=1, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "def calculate_atr_18(df, atr_period=18):\n",
        "    \"\"\"\n",
        "    THIS FUNCTION FOR CALCULATE ATR\n",
        "    \"\"\"\n",
        "    df['TR'] = df.apply(\n",
        "        lambda row: max(\n",
        "            row['high'] - row['low'], abs(\n",
        "                row['high'] - row['close']\n",
        "            ),\n",
        "            abs(\n",
        "                row['low'] - row['close']\n",
        "            )\n",
        "        ), axis=1\n",
        "    )\n",
        "\n",
        "    df['atr_18'] = df['TR'].rolling(window=atr_period).mean()\n",
        "\n",
        "    df.drop('TR', axis=1, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "def calculate_atr_20(df, atr_period=20):\n",
        "    \"\"\"\n",
        "    THIS FUNCTION FOR CALCULATE ATR\n",
        "    \"\"\"\n",
        "    df['TR'] = df.apply(\n",
        "        lambda row: max(\n",
        "            row['high'] - row['low'], abs(\n",
        "                row['high'] - row['close']\n",
        "            ),\n",
        "            abs(\n",
        "                row['low'] - row['close']\n",
        "            )\n",
        "        ), axis=1\n",
        "    )\n",
        "\n",
        "    df['atr_20'] = df['TR'].rolling(window=atr_period).mean()\n",
        "\n",
        "    df.drop('TR', axis=1, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "calculate_atr_14(df, 14)\n",
        "\n",
        "calculate_atr_16(df, 16)\n",
        "\n",
        "calculate_atr_18(df, 18)\n",
        "\n",
        "calculate_atr_20(df, 20)\n",
        "\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn0ZkkGDlSx1"
      },
      "source": [
        "### calculate MACD\n",
        "\n",
        "MACD (Moving Average Convergence Divergence) is a popular technical analysis indicator used in stock trading to identify changes in the strength, direction, momentum, and duration of a trend in a stock's price."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnUudvhblT1d"
      },
      "outputs": [],
      "source": [
        "def calculate_macd(df, short_window=12, long_window=26, signal_window=9):\n",
        "    short_ema = df['close'].ewm(span=short_window, adjust=False).mean()\n",
        "\n",
        "    long_ema = df['close'].ewm(span=long_window, adjust=False).mean()\n",
        "\n",
        "    df['macd'] = short_ema - long_ema\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "df = calculate_macd(df)\n",
        "\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XXBi-pSvxga"
      },
      "source": [
        "### calculate ADX (14, 16, 18, 20, 22, 24, 26)\n",
        "\n",
        "ADX (Average Directional Index) is a technical indicator used to quantify the strength of a trend, regardless of its direction. It is part of the Directional Movement System developed by J. Welles Wilder, which also includes the Positive Directional Indicator (+DI) and Negative Directional Indicator (-DI)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24fSuvpgZvKy"
      },
      "outputs": [],
      "source": [
        "def calculate_adx(df, timeperiod=14, high_col='high', low_col='low', close_col='close', adx_col='adx_14'):\n",
        "\n",
        "    df['High-Low'] = df[high_col] - df[low_col]\n",
        "    df['High-PrevClose'] = abs(df[high_col] - df[close_col].shift(1))\n",
        "    df['Low-PrevClose'] = abs(df[low_col] - df[close_col].shift(1))\n",
        "    df['TR'] = df[['High-Low', 'High-PrevClose', 'Low-PrevClose']].max(axis=1)\n",
        "\n",
        "    df['UpMove'] = df[high_col] - df[high_col].shift(1)\n",
        "    df['DownMove'] = df[low_col].shift(1) - df[low_col]\n",
        "    df['PlusDM'] = np.where((df['UpMove'] > df['DownMove']) & (df['UpMove'] > 0), df['UpMove'], 0)\n",
        "    df['MinusDM'] = np.where((df['DownMove'] > df['UpMove']) & (df['DownMove'] > 0), df['DownMove'], 0)\n",
        "\n",
        "    df['ATR'] = df['TR'].rolling(window=timeperiod).mean()\n",
        "\n",
        "    df['PlusDI'] = 100 * (df['PlusDM'].rolling(window=timeperiod).sum() / df['ATR'])\n",
        "    df['MinusDI'] = 100 * (df['MinusDM'].rolling(window=timeperiod).sum() / df['ATR'])\n",
        "\n",
        "    df['RS'] = df['PlusDI'] / df['MinusDI']\n",
        "    df[f'{adx_col}'] = 100 * df['RS'].ewm(span=timeperiod, adjust=False).mean()\n",
        "\n",
        "    df.drop(['High-Low', 'High-PrevClose', 'Low-PrevClose', 'TR', 'UpMove', 'DownMove', 'PlusDM', 'MinusDM', 'ATR', 'RS', 'PlusDI', 'MinusDI'], axis=1, inplace=True)\n",
        "\n",
        "    return None\n",
        "\n",
        "calculate_adx(df, timeperiod = 14, adx_col='adx_14')\n",
        "\n",
        "calculate_adx(df, timeperiod = 16, adx_col='adx_16')\n",
        "\n",
        "calculate_adx(df, timeperiod = 18, adx_col='adx_18')\n",
        "\n",
        "calculate_adx(df, timeperiod = 20, adx_col='adx_20')\n",
        "\n",
        "calculate_adx(df, timeperiod = 22, adx_col='adx_22')\n",
        "\n",
        "calculate_adx(df, timeperiod = 24, adx_col='adx_24')\n",
        "\n",
        "calculate_adx(df, timeperiod = 26, adx_col='adx_26')\n",
        "\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuYYJN24UUQ0"
      },
      "source": [
        "### calculate vix (14, 16, 18, 20)\n",
        "\n",
        "The VIX (Volatility Index), often referred to as the \"Fear Gauge\" or \"Fear Index,\" is a popular measure of the stock market's expectation of volatility based on S&P 500 index options. It is calculated and published by the Chicago Board Options Exchange (CBOE) and represents the market's expectations for volatility over the next 30 days."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEbEo3DoOgjw"
      },
      "outputs": [],
      "source": [
        "def calculate_vix(df, timeperiod=20, high_col='high', low_col='low', close_col='close', vix_col='vix_20'):\n",
        "\n",
        "    # Calculate log returns\n",
        "    df['LogReturns'] = np.log(df[close_col] / df[close_col].shift(1))\n",
        "\n",
        "    # Calculate squared returns\n",
        "    df['SquaredReturns'] = df['LogReturns'].pow(2)\n",
        "\n",
        "    # Calculate rolling sum of squared returns\n",
        "    df['SumSquaredReturns'] = df['SquaredReturns'].rolling(window=timeperiod).sum()\n",
        "\n",
        "    # Calculate VIX\n",
        "    df[vix_col] = 100 * np.sqrt(df['SumSquaredReturns'] * (252 / timeperiod))\n",
        "\n",
        "    # Drop temporary columns\n",
        "    df.drop(['LogReturns', 'SquaredReturns', 'SumSquaredReturns'], axis=1, inplace=True)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "calculate_vix(df, timeperiod = 14, vix_col='vix_14')\n",
        "\n",
        "calculate_vix(df, timeperiod = 16, vix_col='vix_16')\n",
        "\n",
        "calculate_vix(df, timeperiod = 18, vix_col='vix_18')\n",
        "\n",
        "calculate_vix(df, timeperiod = 20, vix_col='vix_20')\n",
        "\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQhjAcjmI0Ar"
      },
      "source": [
        "### calculate target (close - next close)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uESwd0YBIzwU"
      },
      "outputs": [],
      "source": [
        "df['target'] = df['close'].shift(-1) - df['close']\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeS7jWfmf1J5"
      },
      "source": [
        "# visulize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToP4rqbDf3kz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE4rOa0R_RMa"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reshape and scalar data and test train data"
      ],
      "metadata": {
        "id": "BDA9J9YDpSSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(\"target\", axis=1)\n",
        "\n",
        "y = df[\"target\"]\n",
        "\n",
        "scaler_X = StandardScaler()\n",
        "\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "y_scaled = scaler_y.fit_transform(\n",
        "    y.values.reshape(-1, 1)\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled,\n",
        "    y_scaled,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_train = X_train.reshape(\n",
        "    X_train.shape[0],\n",
        "    X_train.shape[1],\n",
        "    1\n",
        ")\n",
        "\n",
        "X_test = X_test.reshape(\n",
        "    X_test.shape[0],\n",
        "    X_test.shape[1],\n",
        "    1\n",
        ")"
      ],
      "metadata": {
        "id": "1JOZkS7SpXi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is LSTM?\n",
        "\n",
        "LSTM (Long Short-Term Memory) is a type of Recurrent Neural Network (RNN) specifically designed to overcome the limitations of traditional RNNs in processing and predicting time series and sequential data. Unlike standard RNNs, which can struggle with issues like vanishing and exploding gradients, LSTMs are capable of maintaining information over long periods.\n",
        "\n",
        "### Structure of LSTM\n",
        "\n",
        "LSTM networks include memory units known as \"cells,\" which control the flow of information through three different gates:\n",
        "1. **Forget Gate**: Decides how much of the past information should be discarded.\n",
        "2. **Input Gate**: Determines how much of the new information should be added to the memory.\n",
        "3. **Output Gate**: Decides how much of the memory information should be used to produce the output.\n",
        "\n",
        "This structure allows LSTMs to retain information for longer periods and is therefore well-suited for learning long-term patterns in sequential data.\n",
        "\n",
        "### Applications of LSTM\n",
        "\n",
        "1. **Time Series Forecasting**: LSTMs are widely used for predicting future values in time series, such as stock prices, product demand, and weather forecasting.\n",
        "\n",
        "2. **Natural Language Processing (NLP)**: In NLP applications such as sentiment analysis, machine translation, and text generation, LSTMs can model long-term dependencies between words.\n",
        "\n",
        "3. **Speech Recognition**: In speech-to-text conversion and speech analysis, LSTMs perform well because they can handle long sequences of audio data.\n",
        "\n",
        "4. **Human Activity Recognition**: For analyzing sensor data to recognize human activities or predict behavior based on motion data.\n",
        "\n",
        "5. **Financial Series Prediction**: For analyzing and predicting asset prices and other financial metrics due to the presence of complex and long-term patterns.\n",
        "\n",
        "### Advantages of LSTM\n",
        "\n",
        "- **Long-Term Information Retention**: Unlike traditional RNNs, LSTMs can hold onto information for extended periods.\n",
        "- **Mitigation of Vanishing and Exploding Gradient Problems**: The unique structure of LSTM helps to control these issues."
      ],
      "metadata": {
        "id": "1xRsoeQ0KAik"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXo9HxLPjtI2"
      },
      "source": [
        "### compile model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data preparation\n",
        "# Assume df contains several features (e.g., open, close, high, low, volume, etc.)\n",
        "X = df.drop(\"target\", axis=1)  # Use 'target' for future price\n",
        "y = df[\"target\"]  # This could be the target future price\n",
        "\n",
        "# Data scaling\n",
        "scaler_X = StandardScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "scaler_y = StandardScaler()\n",
        "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))  # Scaling y for continuous models\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape data for LSTM and GRU models\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Create LSTM model\n",
        "def create_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]),\n",
        "                   kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(units=32, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(units=1, activation='linear', kernel_regularizer=l2(0.01)))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return model\n",
        "\n",
        "# Create GRU model\n",
        "def create_gru_model():\n",
        "    model = Sequential()\n",
        "    model.add(GRU(units=64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]),\n",
        "                  kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(GRU(units=32, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(units=1, activation='linear', kernel_regularizer=l2(0.01)))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return model\n",
        "\n",
        "# Train models\n",
        "def train_model(model, X_train, y_train, X_test, y_test):\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "    return history\n",
        "\n",
        "# Create and train LSTM and GRU models\n",
        "lstm_model = create_lstm_model()\n",
        "gru_model = create_gru_model()\n",
        "\n",
        "print(\"Training LSTM model...\")\n",
        "lstm_history = train_model(lstm_model, X_train, y_train, X_test, y_test)\n",
        "print(\"Training GRU model...\")\n",
        "gru_history = train_model(gru_model, X_train, y_train, X_test, y_test)\n",
        "\n",
        "# Evaluate models\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_test_original = scaler_y.inverse_transform(y_test)\n",
        "    y_pred_original = scaler_y.inverse_transform(y_pred)\n",
        "    mae = mean_absolute_error(y_test_original, y_pred_original)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_original, y_pred_original))\n",
        "    return mae, rmse\n",
        "\n",
        "print(\"Evaluating LSTM model...\")\n",
        "lstm_mae, lstm_rmse = evaluate_model(lstm_model, X_test, y_test)\n",
        "print(f'LSTM Mean Absolute Error (MAE): {lstm_mae}')\n",
        "print(f'LSTM Root Mean Squared Error (RMSE): {lstm_rmse}')\n",
        "\n",
        "print(\"Evaluating GRU model...\")\n",
        "gru_mae, gru_rmse = evaluate_model(gru_model, X_test, y_test)\n",
        "print(f'GRU Mean Absolute Error (MAE): {gru_mae}')\n",
        "print(f'GRU Root Mean Squared Error (RMSE): {gru_rmse}')\n",
        "\n",
        "# Improved auto-regressive prediction using ensemble of models\n",
        "def auto_regressive_prediction(models, initial_input, n_steps=10):\n",
        "    predictions = np.zeros((n_steps, len(models)))\n",
        "\n",
        "    for i, model in enumerate(models):\n",
        "        current_input = initial_input.copy()\n",
        "        for step in range(n_steps):\n",
        "            pred = model.predict(current_input[np.newaxis, :, :])\n",
        "            predictions[step, i] = pred[0, 0]\n",
        "            current_input = np.roll(current_input, shift=-1, axis=0)\n",
        "            current_input[-1] = pred\n",
        "\n",
        "    avg_predictions = np.mean(predictions, axis=1)\n",
        "    return avg_predictions\n",
        "\n",
        "# Generate improved auto-regressive predictions using ensemble of models\n",
        "n_steps = 10  # Number of steps to predict\n",
        "models = [lstm_model, gru_model]  # Add more models to the list for a true ensemble approach\n",
        "auto_regressive_preds = auto_regressive_prediction(models, X_test[0], n_steps=n_steps)\n",
        "\n",
        "# Convert predictions back to original scale\n",
        "auto_regressive_preds_original = scaler_y.inverse_transform(np.array(auto_regressive_preds).reshape(-1, 1))\n",
        "\n",
        "# Print auto-regressive predictions\n",
        "print(f'Auto-regressive Predictions: {auto_regressive_preds_original.flatten()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBB3AgdaIskM",
        "outputId": "3372f2ea-2b27-406f-8448-72fc9d9edb27"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LSTM model...\n",
            "Epoch 1/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - loss: 1.5902 - mean_squared_error: 1.0636 - val_loss: 0.9776 - val_mean_squared_error: 0.9683\n",
            "Epoch 2/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 1.0370 - mean_squared_error: 1.0314 - val_loss: 0.9699 - val_mean_squared_error: 0.9691\n",
            "Epoch 3/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 24ms/step - loss: 1.0407 - mean_squared_error: 1.0402 - val_loss: 0.9689 - val_mean_squared_error: 0.9688\n",
            "Epoch 4/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - loss: 0.9817 - mean_squared_error: 0.9816 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
            "Epoch 5/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - loss: 0.9955 - mean_squared_error: 0.9955 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
            "Epoch 6/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - loss: 0.9844 - mean_squared_error: 0.9844 - val_loss: 0.9689 - val_mean_squared_error: 0.9689\n",
            "Epoch 7/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 24ms/step - loss: 1.0409 - mean_squared_error: 1.0409 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
            "Epoch 8/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - loss: 0.9917 - mean_squared_error: 0.9917 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
            "Epoch 9/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 24ms/step - loss: 1.0196 - mean_squared_error: 1.0196 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
            "Epoch 10/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - loss: 1.0032 - mean_squared_error: 1.0032 - val_loss: 0.9689 - val_mean_squared_error: 0.9688\n",
            "Epoch 11/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - loss: 0.9796 - mean_squared_error: 0.9795 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
            "Epoch 12/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - loss: 0.9959 - mean_squared_error: 0.9959 - val_loss: 0.9689 - val_mean_squared_error: 0.9689\n",
            "Epoch 13/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - loss: 0.9802 - mean_squared_error: 0.9802 - val_loss: 0.9690 - val_mean_squared_error: 0.9689\n",
            "Epoch 14/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - loss: 1.0023 - mean_squared_error: 1.0023 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
            "Epoch 15/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - loss: 1.0255 - mean_squared_error: 1.0255 - val_loss: 0.9689 - val_mean_squared_error: 0.9689\n",
            "Epoch 16/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - loss: 0.9353 - mean_squared_error: 0.9353 - val_loss: 0.9690 - val_mean_squared_error: 0.9690\n",
            "Epoch 17/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 24ms/step - loss: 1.0341 - mean_squared_error: 1.0341 - val_loss: 0.9689 - val_mean_squared_error: 0.9688\n",
            "Epoch 18/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - loss: 0.9818 - mean_squared_error: 0.9818 - val_loss: 0.9689 - val_mean_squared_error: 0.9689\n",
            "Training GRU model...\n",
            "Epoch 1/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - loss: 1.5247 - mean_squared_error: 0.9946 - val_loss: 0.9828 - val_mean_squared_error: 0.9701\n",
            "Epoch 2/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - loss: 1.0359 - mean_squared_error: 1.0277 - val_loss: 0.9704 - val_mean_squared_error: 0.9688\n",
            "Epoch 3/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - loss: 0.9744 - mean_squared_error: 0.9733 - val_loss: 0.9691 - val_mean_squared_error: 0.9689\n",
            "Epoch 4/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - loss: 1.0226 - mean_squared_error: 1.0225 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
            "Epoch 5/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - loss: 1.0169 - mean_squared_error: 1.0169 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
            "Epoch 6/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - loss: 0.9990 - mean_squared_error: 0.9990 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
            "Epoch 7/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - loss: 0.9931 - mean_squared_error: 0.9931 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
            "Epoch 8/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - loss: 1.0209 - mean_squared_error: 1.0209 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
            "Epoch 9/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - loss: 1.0049 - mean_squared_error: 1.0049 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
            "Epoch 10/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - loss: 0.9883 - mean_squared_error: 0.9883 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
            "Epoch 11/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - loss: 0.9737 - mean_squared_error: 0.9737 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
            "Epoch 12/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 34ms/step - loss: 1.0263 - mean_squared_error: 1.0263 - val_loss: 0.9689 - val_mean_squared_error: 0.9689\n",
            "Epoch 13/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 29ms/step - loss: 1.0344 - mean_squared_error: 1.0344 - val_loss: 0.9690 - val_mean_squared_error: 0.9688\n",
            "Epoch 14/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - loss: 0.9932 - mean_squared_error: 0.9931 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
            "Epoch 15/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - loss: 0.9731 - mean_squared_error: 0.9731 - val_loss: 0.9689 - val_mean_squared_error: 0.9689\n",
            "Epoch 16/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - loss: 1.0601 - mean_squared_error: 1.0601 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
            "Evaluating LSTM model...\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "LSTM Mean Absolute Error (MAE): 0.0006879547301722923\n",
            "LSTM Root Mean Squared Error (RMSE): 0.0010482739955450543\n",
            "Evaluating GRU model...\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "GRU Mean Absolute Error (MAE): 0.000687965515327262\n",
            "GRU Root Mean Squared Error (RMSE): 0.0010482751187726718\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Auto-regressive Predictions: [-3.04556479e-06 -3.04556479e-06 -3.04556473e-06 -3.04556467e-06\n",
            " -3.04556467e-06 -3.04556467e-06 -3.04556467e-06 -3.04556467e-06\n",
            " -3.04556467e-06 -3.04556467e-06]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}